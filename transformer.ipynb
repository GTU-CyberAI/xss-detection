{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"dmzo_nomal.csv\", usecols=[0], nrows=30000, header=None, names=[\"Sentence\"])\n",
    "df1[\"Label\"] = 0  # Normal veriye etiket 0\n",
    "\n",
    "df2 = pd.read_csv(\"xssed.csv\", usecols=[0], nrows=30000, header=None, names=[\"Sentence\"])\n",
    "df2[\"Label\"] = 1  # XSS zararlı veriye etiket 1\n",
    "\n",
    "# Veri kümesini birleştir ve karıştır\n",
    "df = pd.concat([df1, df2], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Metin ve etiketleri listeye çevir\n",
    "texts = df[\"Sentence\"].astype(str).tolist()\n",
    "labels = df[\"Label\"].astype(int).tolist()  # Label'ları integer'a çevir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1  # +1 for padding index\n",
    "maxlen = 100\n",
    "X = pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
    "y = np.array(labels)\n",
    "\n",
    "# 2. Eğitim/test ayrımı\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64  # Embedding boyutu\n",
    "num_heads = 2\n",
    "ff_dim = 128  # Feed-forward katman boyutu\n",
    "\n",
    "input_layer = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim)(input_layer)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)(embedding_layer)\n",
    "flattened = tf.keras.layers.GlobalAveragePooling1D()(transformer_block)\n",
    "dense = Dense(64, activation=\"relu\")(flattened)\n",
    "dropout = Dropout(0.2)(dense)\n",
    "output = Dense(1, activation=\"sigmoid\")(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 64)           4235520   \n",
      "                                                                 \n",
      " transformer_block (Transfo  (None, 100, 64)           50048     \n",
      " rmerBlock)                                                      \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 64)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4289793 (16.36 MB)\n",
      "Trainable params: 4289793 (16.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 101s 66ms/step - loss: 0.0627 - accuracy: 0.9804 - val_loss: 0.0347 - val_accuracy: 0.9902\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 103s 69ms/step - loss: 0.0240 - accuracy: 0.9934 - val_loss: 0.0410 - val_accuracy: 0.9913\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 105s 70ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0477 - val_accuracy: 0.9914\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 106s 70ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0428 - val_accuracy: 0.9908\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 102s 68ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0636 - val_accuracy: 0.9893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunus\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# 5. Eğit\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_test, y_test))\n",
    "\n",
    "# 6. Kaydet\n",
    "model.save(\"xss_transformer_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 135ms/step\n",
      "Predicted output: [[0.9999942]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"xss_transformer_model.h5\", custom_objects={\"TransformerBlock\": TransformerBlock})\n",
    "input_text = \"<svg src=x onerror=alert(0)>\"  # Test metni\n",
    "input_seq = tokenizer.texts_to_sequences([input_text])\n",
    "maxlen = 100   \n",
    "input_seq_padded = pad_sequences(input_seq, maxlen=maxlen, padding='post')\n",
    "\n",
    "output = model.predict(input_seq_padded)\n",
    "\n",
    "print(f\"Predicted output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tokenizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenizer, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
